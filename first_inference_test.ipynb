{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first-inference-test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SheetMusic-Team-3/semantic-music-model/blob/main/first_inference_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGA9PijccBM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c52bc843-0fe2-47e0-f360-77ca28c01428"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9KtGVonm55C"
      },
      "source": [
        "# import top-level dependencies\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageDraw\n",
        "from zipfile import ZipFile\n",
        "import glob\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-RJGIZdiqXf",
        "outputId": "939452ea-acdf-4781-b7ee-b4ca36ae271b"
      },
      "source": [
        "# mount drive if not already mounted\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU7b-5Xao7Nf",
        "outputId": "ce63d243-e7d3-4890-a21d-489b47e94cef"
      },
      "source": [
        "# copy modules to path\n",
        "% env PATH_TO_TEAM_FOLDER=/content/drive/MyDrive\n",
        "% cp -r $PATH_TO_TEAM_FOLDER/Team_3_cs121S21/'Work Products'/'Semantic Model Inference'/ .\n",
        "% cd 'Semantic Model Inference'\n",
        "% ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: PATH_TO_TEAM_FOLDER=/content/drive/MyDrive\n",
            "cp: cannot open '/content/drive/MyDrive/Team_3_cs121S21/Work Products/Semantic Model Inference/test-set-output/test-alpha-69.gdoc' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/Team_3_cs121S21/Work Products/Semantic Model Inference/test-set-output/test-alpha-74.gdoc' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/Team_3_cs121S21/Work Products/Semantic Model Inference/test-set-output/test-alpha-79.gdoc' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/Team_3_cs121S21/Work Products/Semantic Model Inference/test-set-output/test-alpha-3.gdoc' for reading: Operation not supported\n",
            "cp: cannot open '/content/drive/MyDrive/Team_3_cs121S21/Work Products/Semantic Model Inference/test-set-output/test-alpha-4.gdoc' for reading: Operation not supported\n",
            "/content/Semantic Model Inference\n",
            "ctc_utils.py                \u001b[0m\u001b[01;34mimages\u001b[0m/           \u001b[01;34mtest-set\u001b[0m/\n",
            "first-inference-test.ipynb  \u001b[01;34mmodel-artifacts\u001b[0m/  \u001b[01;34mtest-set-output\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C9_H3Smrb6v"
      },
      "source": [
        "# import modules\n",
        "import ctc_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiWIHX2Gqb6F"
      },
      "source": [
        "model_zip_path=\"./model-artifacts/Semantic-Model.zip\"\n",
        "# extract model files from zip\n",
        "with ZipFile(model_zip_path, 'r') as zipObj:\n",
        "   zipObj.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLQB-YBYjxfA"
      },
      "source": [
        "voc_path=\"./model-artifacts/vocab.txt\"\n",
        "model_path=\"./semantic-model.meta\"\n",
        "image_folder = \"./test-set\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNuCPwiONXL-"
      },
      "source": [
        "output_image_folder=\"./test-set-output\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7JSqZQvlt6n",
        "outputId": "8958e143-9df4-496b-9c0a-e96776326a09"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "# Read the dictionary\n",
        "dict_file = open(voc_path,'r')\n",
        "dict_list = dict_file.read().splitlines()\n",
        "int2word = dict()\n",
        "for word in dict_list:\n",
        "    word_idx = len(int2word)\n",
        "    int2word[word_idx] = word\n",
        "dict_file.close()\n",
        "\n",
        "# Restore weights\n",
        "saver = tf.train.import_meta_graph(\"semantic_model.meta\")\n",
        "saver.restore(sess,\"semantic_model.meta\"[:-5])\n",
        "\n",
        "graph = tf.get_default_graph()\n",
        "\n",
        "input = graph.get_tensor_by_name(\"model_input:0\")\n",
        "seq_len = graph.get_tensor_by_name(\"seq_lengths:0\")\n",
        "rnn_keep_prob = graph.get_tensor_by_name(\"keep_prob:0\")\n",
        "height_tensor = graph.get_tensor_by_name(\"input_height:0\")\n",
        "width_reduction_tensor = graph.get_tensor_by_name(\"width_reduction:0\")\n",
        "logits = tf.get_collection(\"logits\")[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The saved meta_graph is possibly from an older release:\n",
            "'model_variables' collection should be of type 'byte_list', but instead is of type 'node_list'.\n",
            "INFO:tensorflow:Restoring parameters from semantic_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XluA3G-j2Pf8"
      },
      "source": [
        "#Single Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "VhnMfxgA2Q5e",
        "outputId": "56571c70-243f-451a-e132-7688e96d4429"
      },
      "source": [
        "file_name = \"./images/test1.png\"\n",
        "\n",
        "WIDTH_REDUCTION, HEIGHT = sess.run([width_reduction_tensor, height_tensor])\n",
        "\n",
        "decoded, _ = tf.nn.ctc_greedy_decoder(logits, seq_len)\n",
        "\n",
        "image = cv2.imread(file_name,False)\n",
        "#show image\n",
        "cv2_imshow(image)\n",
        "image = ctc_utils.resize(image, HEIGHT)\n",
        "image = ctc_utils.normalize(image)\n",
        "image = np.asarray(image).reshape(1,image.shape[0],image.shape[1],1)\n",
        "\n",
        "seq_lengths = [ image.shape[2] / WIDTH_REDUCTION ]\n",
        "\n",
        "prediction = sess.run(decoded,\n",
        "                      feed_dict={\n",
        "                          input: image,\n",
        "                          seq_len: seq_lengths,\n",
        "                          rnn_keep_prob: 1.0,\n",
        "                      })\n",
        "\n",
        "str_predictions = ctc_utils.sparse_tensor_to_strs(prediction)\n",
        "for w in str_predictions[0]:\n",
        "    print(int2word[w])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABBAAAACaCAAAAAA1auSBAAALAklEQVR4nO2dWbqsKgxGOee7M2L+Q2BM5z5Uadmg0gQJZK2HvauhFCH8hi7++efs4bdvwl2C2JcA8/LHniD40yfhLgGaAIYwJwjeuV8jX5p+OCbYgSSAGawJwk4PIn0Dv3lHxwHM8bd3Bt7loAeHL/Z64MLRkQCYHVuC8GnZ/tfA4/d+f1QAFAGMYEsQFiIN3O8+/76grwDGsCkIz7d8fAIwiSlB8NGXl5+kfgkwDaYEAQDuQRCSYDABbGBKEB6bdTi8oqcAxjAlCGeOLR5PAGzzX+8MdOLc8sP3r/99y1JFsIYtQQgJfYCbdc0As2NtL8N+cfJGH06NHjkAg9jyENynT/C0R2H7OXIAljDnIWy48g+IhwBmMSwId/2F56BKADNiVxCetjzeCwbAlJgVhJT9jI+aATAZVgVhN9nwkColJcAUmJtl+LBZfRT5huYPVjHpIcQavQ/rN5svcRHAFhb3Mni3iZe4+ewcMQnAGPa6DLumf3nf93gEYBF7grDDfzUBjwDAOYOCcGr6t3HVYCRiz92BPKwJQmqbx6ZGYyvs1F4xxgYVr/UguLsdjwiEdvzlG8jBmCCkQvsfi+OjdVCEUsQF4fTUI01k5g0HYRA029xgCI8hjFEz4ZzPbwC1C8cTPVDNjdV5Ki8Pa4OKbhktiAc9WBSBkAhz4B1DjHnYG0MIu3/HN8cVjPGPQBPXDoJ/+B5OmPMQwuZFdN467CwIMQBT2BKE4C8cg0OyF7ICUrR3ACwteLIlCCaqFETr2diCJ3tjCDA/Yfe/qhlbW/CEIMDERNefZmBvwVPnLoPHiQdxQvRlAfO3/xN9BcFggUNr5G4xFs2TLgPMBS5nFcZmGWByJOXAooPg/vyzed0AEOEvegAAC3/pcwHAgvBzGa4fgHKVPCX19qirQ6NSyEbebTtA3qNZbDV1HXGdE050U4pZW2i77Lf1Q8wy+J3KrC/o6sBIZK1x6rcgSr8gHMsCRYBOVK15bJZYFv2C8CFWRChCZ1SHyxMn1FzvKHqgXxCWwrFlfEPgTdWK9vEVIeQFITjnvPfypnI+oB1r1IipcETfsFmlVzuMg9BAEPxqKkZsxSgGancNnmcoil6Dpcs/S7EQUCKJbps6n55pm38oK67zh32ArWINbOsgiFpX2zEEA3eRRHqUxK/bVu2sbXqAJoWhAVnld5fYi1pXG0EIhnysRF5XhL0IVJ3+7lBUdBlieuCck7SuFoIQfnFqcBGcc9+B1ndPeTxdxekvDhWCqc71B4UGLVsFwoJQG7IqfsQdCqskjVczLniymwfkWpMDOSQdBNHbjfp1CJFFy+ev1BOce1URXtEDKCbkjOokJZaqJv2CcHjU0qD2+a4ioAdNkLoBhZz5ioTEksbVOGJSWhH6+6RhM7Hid58DDMdyZ0sy34zEMpP8REwCgBUiJgHAChGTAGBFOGLSGjDmYVjgl9ptp02SosgkKlhm8KZc4odPiJfzggALxvopO1QrXo6YdDxuikklZvHmUEXnlVmj3jhiUmLuUi/iM/ky/Nx3ly6aYKGNXv5TU29cjQThpGnXU6mpD+ScQw5cF0VAD6xQbVxtBOGsB5dJUzsA3p3kwNxwaOkepSAXnQI9kEF2K8N2h3F+Xna0WIdwHj+oNsf4kMSg26sLs+3dtoea0XPGP4BkWsVDkLWcXXCe2BolA5ReLnIgyfRF0GilYna53aqIP77br2Yegs01VD6iPGUvy7rc9RejuvSsQTLKytDovQMJ5qyJIAibTnkwRb1VWMfzdUlWQVslIOCKKLXF2CQeguzvpmjVYg7C4WBpqG1skUhMkI2kcTXwEEryNLs1SFbZPB78oSuo/Ioar3QrR7TxiHsI0ZUCCcu7ChwElbUTZXa9K0MwqBN8qG8S0oJQlKMG8xKqENmzXVs+6pqbugzdI5tdwTjMshnTECAlZYYhErZ1YgWJslzvpySGv/rB9MA5p7PQhSOENA6QkkKCf/BpAiOa0JGaKtNojsXMUJkqEG4W3T2E2JrkI8uygxD5cAT6Z7V/DkZH7ZDiBon8ETEJAFaImAQAK0RMAoCVTcSk1VVYFstvA58fgqDnqshFJKGbAEOxtCspP3rB88mJmCS4nOixO9s01o8MokGdmkdMypgXT8ribXVkJd7kT2bN2/Og4m7QT3inYSi7hhGdGrk8T9rHU1yp6ktcsOweBcGvf3anFlMEM4he6nzlpviKskJ59kEuc0+C8G34ftef2HzxGqK7g/pRX2zqb1dFCAZ1kkY+X1lTmGmJw5K0luR1CKeTdau/UfWgc75VF5vizM2zlyyJV1cqivhe3yHPASsoeCe0p69gTFcziuuyRbSGBg6CnHHlr1TcD73m4Hf/KlBu3zHEPOIBrz3Ob6Bab0w8td2YPX61rvr8vuchbALDFujYdgwj/aob3nryt6stdab4fvgu6gviPJYue1ShxIdx/zpq9jIU56Ei8+qNKMYpJmQHtBec6vyJ60HqAVMS+8s3Jby6uWndw1za21jXTA1NzQUUhY4YvsQmoq0e1Nf1kyBIB+vsEFCwO+PlGHao9l6OVFrbo4dwXKNYTM1T2DYOwgyt6+VrGGHnrnNObd0Klp3PcRCSEkuX2XOXIQRX15oPh6v7rVKbyaRu9GWIxg0RxMcTJX/3IWWWobsB/taGDK4HpUMoVQxSZmoDYonvQkneJZV39tW4quax+oRQ6y4xfRDrfhWfGbIRK7qsNU75C6KEjIuISQCwQsQkAFghYhIArCRETDpSsqBz3Y2UPwW22xHVZjGpHNeRodyLWW4Y60cKwaBOrSib0bkoxZXnA+Zu9Bc0rqSISaI7PEoPpbP5J9Mt+0xTKiOrLtIS/+60EiQtXb44Wb6hFdjnHCYtFr8iD8aHKpE2vAZ6IJzJ52nHo1FVGFmpHsTOOUBcqy1dZtkHKyMoRC7Qxrubm7yTXPI4GB22ZeEf1DKEg+BEHdA0QYieK7O0/DBL6tvwtiIsQz+DFLkF62ilB5KKUL5SsaT28n9z+IX2WYY7Xu017KaMYHqC1M3mURC+nfjywGk/rNvmi9dPb0Eh7RyEoh/ESfUQFkWouPNY14PX2KrBSIWuLK/KsvMST4Lgty9CjSNqs3w7M0yhG3Bp2joIUmTNMpTrQeEz2wDgVR4EISoBJVOHMnpg4D4iyjAqbGCOYQwH4aHLsNEDbdVFNPNnKCLI5U4QlM3xncLLqsgVCIDnp4ZXw7BXgdHkMpZgjpXbbAbpMRAxCQB+EDEJAFaImAQAK3cRk34gGiMhuev5hYhJc0S8mIW7QcWwrzMYiWFaGLalivt1COtaZR+UzUHCJBDERRcP044xH8FLBlkE26AHyshah0AXYhgGaWIYkjaedjuuXYXw+fN9yzJBqCf/eWXQmlQPod9jCWFS6Hlq5FEQwubv9hW1qZYgqNvtguIySq2S8r0MKIJaxgptPVRmpydNEKJ1hiIAzMY4ux1hTnAQVPEsCMcKowJBEMxJF0kewuNjoAHKQA+UkRCGnToDsAJjCNARbjbaQBAAYAVBgH7gIKgDQYBuoAf6QBAAYCXlYa8eLYcGYFQKeRYE//lD7QHMz2OXwR/+A8C8PAkCOgCNwOfUCIOKALBSIwhIPMBk4CFAH7idqCRl2nHP7gFPAEVgPErBQwCAlWRBOEk6Gg8wHU+C8G3258c8ogcA85EWhv3X+tEDgIlJi6noj+sV0QOAGUkJoebdYcUicgAwJ1cewvbpP4fnfoz1GBAASOfPv945AAA1/A+/EIETLtoybQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=1040x154 at 0x7F4E99E73690>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "clef-C1\n",
            "keySignature-EbM\n",
            "timeSignature-2/4\n",
            "multirest-23\n",
            "barline\n",
            "rest-quarter\n",
            "rest-eighth\n",
            "note-Bb4_eighth\n",
            "barline\n",
            "note-Bb4_quarter.\n",
            "note-G4_eighth\n",
            "barline\n",
            "note-Eb5_quarter.\n",
            "note-D5_eighth\n",
            "barline\n",
            "note-C5_eighth\n",
            "note-C5_eighth\n",
            "rest-quarter\n",
            "barline\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjs3IkYH1paC"
      },
      "source": [
        "# Batch Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKejXkidl01E"
      },
      "source": [
        "# run batch inference\n",
        "for image_path in glob.glob(f'{image_folder}/*.png'):\n",
        "\n",
        "  # create text file\n",
        "  file_name = image_path.split(\"/\")[2][:-4]\n",
        "  if not os.path.exists(output_image_folder):\n",
        "    os.makedirs(output_image_folder)\n",
        "  out_file= open(f'{output_image_folder}/{file_name}.txt',\"w+\")\n",
        "\n",
        "  WIDTH_REDUCTION, HEIGHT = sess.run([width_reduction_tensor, height_tensor])\n",
        "\n",
        "  decoded, _ = tf.nn.ctc_greedy_decoder(logits, seq_len)\n",
        "\n",
        "  image = cv2.imread(image_path,False)\n",
        "  image = ctc_utils.resize(image, HEIGHT)\n",
        "  image = ctc_utils.normalize(image)\n",
        "  image = np.asarray(image).reshape(1,image.shape[0],image.shape[1],1)\n",
        "\n",
        "  seq_lengths = [ image.shape[2] / WIDTH_REDUCTION ]\n",
        "\n",
        "  prediction = sess.run(decoded,\n",
        "                        feed_dict={\n",
        "                            input: image,\n",
        "                            seq_len: seq_lengths,\n",
        "                            rnn_keep_prob: 1.0,\n",
        "                        })\n",
        "\n",
        "  str_predictions = ctc_utils.sparse_tensor_to_strs(prediction)\n",
        "\n",
        "  for w in str_predictions[0]:\n",
        "      out_file.write(int2word[w])\n",
        "      out_file.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}